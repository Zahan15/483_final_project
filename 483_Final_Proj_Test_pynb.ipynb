{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zahan15/483_final_project/blob/master/483_Final_Proj_Test_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWhUwO_-mL2s"
      },
      "source": [
        "## GNN for link prediction and graph classification task\n",
        "\n",
        "Last time we explore a standard benchmark datase Cora, and implement a classic graph neural network GCN(Kipf et al. (2017)) for node classification task. In this Colab, we are going to explore two kinds of graph learning task: **link prediction** and **graph classification**. We will apply GCN to both of these two tasks. All of these implementations are still based on the [PyG](https://pytorch-geometric.readthedocs.io/en/latest/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R0-JXHoqhtD"
      },
      "source": [
        "## Outline\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETQPVYpoqsvY"
      },
      "source": [
        "- Link prediction task\n",
        "- Graph classification task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Q4_xAy_J-WJp",
        "outputId": "88d4a469-79d1-4e51-f33d-b56dec7a5838",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using torch 1.13.0+cu116\n"
          ]
        }
      ],
      "source": [
        "# import the pytorch library into environment and check its version\n",
        "import os\n",
        "import torch\n",
        "print(\"Using torch\", torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC5DJkYNWGeL"
      },
      "source": [
        "Let's start installing PyG by `pip`. The version of PyG should match the current version of PyTorch. Here we follow the [instruction](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html) of PyG:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NWtNbC9FgZOM",
        "outputId": "50c39bd3-48c4-45ce-dd8b-d2983678051a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.8/dist-packages (2.1.0+pt113cu116)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.8/dist-packages (0.6.15+pt113cu116)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.8/dist-packages (1.6.0+pt113cu116)\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.8/dist-packages (1.2.1+pt113cu116)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.8/dist-packages (2.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (5.9.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ogb in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from ogb) (1.0.2)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.8/dist-packages (from ogb) (1.24.3)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.8/dist-packages (from ogb) (4.64.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from ogb) (1.13.0+cu116)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from ogb) (1.3.5)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ogb) (0.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from ogb) (1.21.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from ogb) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from outdated>=0.2.0->ogb) (2.23.0)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.8/dist-packages (from outdated>=0.2.0->ogb) (0.2.2)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.8/dist-packages (from outdated>=0.2.0->ogb) (57.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->ogb) (2022.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->ogb) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->ogb) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->ogb) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6.0->ogb) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->outdated>=0.2.0->ogb) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->outdated>=0.2.0->ogb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->outdated>=0.2.0->ogb) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
        "!pip install ogb  # for datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import some required libraries into our environment:"
      ],
      "metadata": {
        "id": "Xis2aKwZI5YW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "from torch_geometric.datasets import SNAPDataset\n",
        "from torch_geometric import nn\n",
        "import torch_geometric.transforms as T"
      ],
      "metadata": {
        "id": "9JDyVPnhJlq8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Link prediction task"
      ],
      "metadata": {
        "id": "cqa3EchaJiQS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei5_O8ZXtlGb"
      },
      "source": [
        "\n",
        "### Dataset preprocess\n",
        "\n",
        "As shown in the following figure, link prediction is to predict whether two nodes in a graph have a link, which can be considered as a binary classification task. We will construct a link prediction dataset containing training, validation, and test set based on Cora. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNeApmAljKyq"
      },
      "source": [
        "\n",
        "<br/>\n",
        "<center>\n",
        "<img src=\"https://github.com/Graph-and-Geometric-Learning/CPSC483-colab/blob/main/fig/link_prediction_example.png?raw=1\" height=\"200\" width=\"200\"/>\n",
        "</center>\n",
        "<br/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given a graph, we divide the initial edge set into three distinct edge sets which represent the training, validation, and test set. Training set and validation set share a same graph structure. Test set contains some edges which does not exist in training and validation set to prevent data leakage.\n",
        "<!-- Training set does not include edges in validation and test set, and the validation split does not include edges in the test split. Validation and test data should not be leaked into the training set. -->"
      ],
      "metadata": {
        "id": "H-iKLSi5OPnN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<br/>\n",
        "<center>\n",
        "<img src=\"https://github.com/Graph-and-Geometric-Learning/CPSC483-colab/blob/main/fig/link_prediction_dataset_split(2).png?raw=1\" height=\"200\" width=\"350\"/>\n",
        "</center>\n",
        "<br/>\n"
      ],
      "metadata": {
        "id": "1DscWvNMZOme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model will be optimized on the training set. We can use `transforms` function in PyG to easily generate the data splits:"
      ],
      "metadata": {
        "id": "l1QqInaaWDA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.Compose([\n",
        "    T.RandomLinkSplit(num_val=0.05,  # ratio of edges including in the validation set\n",
        "                      num_test=0.2,  # ratio of edges including in the test set\n",
        "                      is_undirected=True,\n",
        "                      add_negative_train_samples=False),\n",
        "])\n"
      ],
      "metadata": {
        "id": "eDhm2T8WNdY0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the Cora dataset:"
      ],
      "metadata": {
        "id": "Yy8kRq68apgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = SNAPDataset('/tmp/snap', 'ego-facebook', transform=transform)"
      ],
      "metadata": {
        "id": "MaZoDsHealti"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data will be transformed from a data object to three tuples, where each element represents the corresponding split:"
      ],
      "metadata": {
        "id": "A2mPElioa6Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data, test_data = dataset[0]\n",
        "print(train_data, val_data, test_data, sep=\"\\n\")"
      ],
      "metadata": {
        "id": "DdTGSQyta6mS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d8cadc7-efc0-4b5a-cb78-0d202a554dae"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EgoData(x=[347, 1406], edge_index=[2, 4292], circle=[325], circle_batch=[325], edge_label=[2146], edge_label_index=[2, 2146])\n",
            "EgoData(x=[347, 1406], edge_index=[2, 4292], circle=[325], circle_batch=[325], edge_label=[284], edge_label_index=[2, 284])\n",
            "EgoData(x=[347, 1406], edge_index=[2, 4576], circle=[325], circle_batch=[325], edge_label=[1142], edge_label_index=[2, 1142])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now data object has two attributes of edge: `edge_index` and `edge_label_index`. `edge_index` denotes the graph structure used for performing message passing in GNN. `edge_label_index` denotes the edge index used to calculate loss in training set, or to evaluate the model in validation and test set.\n"
      ],
      "metadata": {
        "id": "dvWso73JQHqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing the statistics of data:"
      ],
      "metadata": {
        "id": "tKcMT7L1i1t7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of the nodes in training, validation and test data are\", train_data.num_nodes, val_data.num_nodes, test_data.num_nodes)\n",
        "print(\"Number of the edges in training, validation and test data are\", train_data.num_edges, val_data.num_edges, test_data.num_edges)\n",
        "print(\"Number of the edge_label_index in training, validation and test data are\", train_data.edge_label_index.shape[1], \n",
        "                                                                                  val_data.edge_label_index.shape[1],\n",
        "                                                                                  test_data.edge_label_index.shape[1])"
      ],
      "metadata": {
        "id": "c5O_NY7DjAFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3ac8811-cf5b-44ce-e93d-ed6c6ab8361b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of the nodes in training, validation and test data are 347 347 347\n",
            "Number of the edges in training, validation and test data are 4292 4292 4576\n",
            "Number of the edge_label_index in training, validation and test data are 2146 284 1142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pipeline"
      ],
      "metadata": {
        "id": "psqGS5Qeb6k6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We constructed the GCN by PyG in the last Colab, and now we simply use the same architecture:"
      ],
      "metadata": {
        "id": "PUlJKeqjjU1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "        self.act = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, node_feature, edge_index):\n",
        "\n",
        "        output = self.conv1(node_feature, edge_index)\n",
        "        output = self.act(output)\n",
        "        output = self.conv2(output, edge_index)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "swSuk_b4kjJa"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing a GCN model:"
      ],
      "metadata": {
        "id": "ovbAm-sPr5vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCN(dataset.num_features, hidden_channels=128, out_channels=64)"
      ],
      "metadata": {
        "id": "HGt4OLrbsJMd"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define an optimizer for model:"
      ],
      "metadata": {
        "id": "fR6hHZ13vEaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "T0MlrXezvKKm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar as the what we do in the node classification task, we first apply the GCN model to produce the representation of each node in the graph. Usually we will use **inner product** to measure the similarity between two node representations to determine how likely it is for these two nodes to be connected."
      ],
      "metadata": {
        "id": "opuOJ1IylYwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 1\n",
        "\n",
        "Following the instruction and implement the function to calculate the inner product:"
      ],
      "metadata": {
        "id": "Gp6ggnEAnLU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_similarity(node_embs, edge_index):\n",
        "    result = torch.tensor([0.] * len(edge_index[0]))\n",
        "\n",
        "    # TODO: Define similarity function.\n",
        "    # 1. calculate the inner product between all the pairs in the edge_index\n",
        "    # Note: the shape of node_embs is [n, h] where n is the number of nodes, and h is the embedding size\n",
        "    # the shape of edge_index is [2, m] where m is the number of edges\n",
        "\n",
        "    ############# Your code here ############\n",
        "    ## (~1 line of code)\n",
        "    node_embs = torch.nn.functional.normalize(node_embs)\n",
        "    for i in range(len(edge_index[0])):\n",
        "      result[i] = torch.dot(node_embs[edge_index[0][i]], node_embs[edge_index[1][i]])\n",
        "\n",
        "    #########################################\n",
        "\n",
        "    return result\n",
        "\n",
        "n, h = 5, 10  # number of nodes and embedding size\n",
        "node_embs = torch.rand(n, h)\n",
        "edge_index = torch.tensor([[0, 1, 2, 3], \n",
        "                           [2, 3, 0, 1]])  # compute the similarity of (0, 2), (1, 3), (2, 0), (3, 1)\n",
        "similarity = compute_similarity(node_embs, edge_index)\n",
        "print(\"Similairty:\", similarity)"
      ],
      "metadata": {
        "id": "I8PPhqrnjULN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "760da042-c1a8-4ea6-8f04-ae8624aa3bb1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similairty: tensor([0.7905, 0.8211, 0.7905, 0.8211])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We optimize the model by minimizing the loss function. Here we consider the link prediction task as a binary classification task (edge exists or no), and apply binary cross entropy loss:"
      ],
      "metadata": {
        "id": "XI4MF409nGmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "CKENBKVlryb1"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The edges in the graph will be taken as the positive examples with label=1 in the loss function. To prevent model from collapse, we usually will feed some **negative examples** to the loss function, which is the non-existing edges in the graph. The number of negative examples should equal to the number of positive ones."
      ],
      "metadata": {
        "id": "Egf8x3Uhs314"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the help of PyG, we can easily perform the negative sampling. Here is an example:"
      ],
      "metadata": {
        "id": "8nkO6tjJuBc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.utils import negative_sampling\n",
        "\n",
        "neg_edge_index = negative_sampling(\n",
        "      edge_index=train_data.edge_index,  # positive edges in the graph\n",
        "      num_nodes=train_data.num_nodes,  # number of nodes\n",
        "      num_neg_samples=5,  # number of negative examples\n",
        "    )\n",
        "\n",
        "print(\"shape of neg_edge_index:\", neg_edge_index.shape)  # [2, num_neg_samples]\n",
        "print(\"negative examples:\", neg_edge_index)"
      ],
      "metadata": {
        "id": "yWc5xDRauO4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5460d46b-1200-4c0e-d93a-ffe5481e9d01"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of neg_edge_index: torch.Size([2, 5])\n",
            "negative examples: tensor([[112,  79, 188, 227, 288],\n",
            "        [ 74,  42, 198, 190, 128]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive examples (`edge_label_index`) will be assigned the label 1, and negative ones will be assigned the label 0. We can obtain the label of positive examples like this:"
      ],
      "metadata": {
        "id": "Vc5IIVnawI4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"positive examples' labels:\", train_data.edge_label)"
      ],
      "metadata": {
        "id": "R7pY2kaUEYv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68fb0fd9-fe7b-469e-d60e-67a889259bb0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive examples' labels: tensor([1., 1., 1.,  ..., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can construct training and testing pipeline, which is similar to what we do in the last Colab. "
      ],
      "metadata": {
        "id": "2e3WTj6UEXz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 2\n",
        "\n",
        "Please follow the instruction and implement a function that trains a model."
      ],
      "metadata": {
        "id": "KvQzDDHYwo8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data, optimizer, loss_fn):\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    # TODO: Define train function.\n",
        "    # 1. put the model into train mode\n",
        "    # 2. clear the gradients calculated from the last batch\n",
        "    # 3. use 'edge_index' to get the node representation by model\n",
        "    # 4. sample the negative examples with the same number of positive ones (edge_label_index)\n",
        "    # 5. concatenate the positive edges and negative edges\n",
        "    # 6. concatenate the labels of positive edges and negative edges\n",
        "    # 7. calculate the similarity between two end nodes to determine the probability that the corresponding edge is present on the graph.\n",
        "    # 8. feed the probability and edge label to the loss function\n",
        "    # 9. calculate the gradients of each parameter\n",
        "    # 10. update the parameters by taking an optimizer step\n",
        "\n",
        "    ############# Your code here ############\n",
        "    ## (~10 line of code)\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model(data.x, data.edge_index)\n",
        "    \n",
        "    neg_edge_index = negative_sampling(\n",
        "      edge_index=train_data.edge_index,  # positive edges in the graph\n",
        "      num_nodes=train_data.num_nodes,  # number of nodes\n",
        "      num_neg_samples=len(data.edge_label),  # number of negative examples\n",
        "    )\n",
        "    # print(neg_edge_index.shape)\n",
        "    train_edge_index = torch.cat((data.edge_label_index, neg_edge_index), dim=1)\n",
        "    train_edge_label = torch.cat((data.edge_label, torch.tensor([0] * len(train_data.edge_label_index[0]))))\n",
        "    # print(train_edge_index.shape)\n",
        "    pred = compute_similarity(data.x, train_edge_index)\n",
        "    loss = loss_fn(pred.clone().detach().requires_grad_(True), train_edge_label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #########################################\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "HrkHekHbxASw"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We usually use [AUC score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) to evaluate the performance of model on binary classification task. The test function is as followed:"
      ],
      "metadata": {
        "id": "WtMJFkVLW3E6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, data):\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index)  # use `edge_index` to perform message passing\n",
        "    out = compute_similarity(out, data.edge_label_index).view(-1).sigmoid()  # use `edge_label_index` to compute the loss\n",
        "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())"
      ],
      "metadata": {
        "id": "BmJ2ZDl4W3b0"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can start to train our model based on `train` and `test` function:"
      ],
      "metadata": {
        "id": "HVnVcrJrX6xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "best_val_auc = final_test_auc = 0\n",
        "for epoch in range(1, epochs + 1):\n",
        "    loss = train(model, train_data, optimizer, loss_fn)\n",
        "    valid_auc = test(model, val_data)\n",
        "    test_auc = test(model, test_data)\n",
        "    if valid_auc > best_val_auc:\n",
        "        best_val_auc = valid_auc\n",
        "        final_test_auc = test_auc\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {valid_auc:.4f}, Test: {test_auc:.4f}')"
      ],
      "metadata": {
        "id": "5KobDKiwYETN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de7ae235-d71a-4579-fa78-4cd98ea52609"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 0.7026, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 002, Loss: 0.7023, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 003, Loss: 0.7020, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 004, Loss: 0.7004, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 005, Loss: 0.7021, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 006, Loss: 0.7004, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 007, Loss: 0.7039, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 008, Loss: 0.7039, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 009, Loss: 0.7016, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 010, Loss: 0.7032, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 011, Loss: 0.7018, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 012, Loss: 0.7019, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 013, Loss: 0.7032, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 014, Loss: 0.7013, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 015, Loss: 0.7022, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 016, Loss: 0.7030, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 017, Loss: 0.7025, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 018, Loss: 0.7023, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 019, Loss: 0.7020, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 020, Loss: 0.7046, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 021, Loss: 0.7018, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 022, Loss: 0.7026, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 023, Loss: 0.7012, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 024, Loss: 0.7022, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 025, Loss: 0.7033, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 026, Loss: 0.7027, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 027, Loss: 0.7019, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 028, Loss: 0.7034, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 029, Loss: 0.7026, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 030, Loss: 0.7028, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 031, Loss: 0.7000, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 032, Loss: 0.7027, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 033, Loss: 0.7040, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 034, Loss: 0.7017, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 035, Loss: 0.7023, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 036, Loss: 0.7004, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 037, Loss: 0.7019, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 038, Loss: 0.7041, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 039, Loss: 0.7015, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 040, Loss: 0.7035, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 041, Loss: 0.7023, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 042, Loss: 0.7010, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 043, Loss: 0.7012, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 044, Loss: 0.6995, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 045, Loss: 0.7017, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 046, Loss: 0.7036, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 047, Loss: 0.7030, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 048, Loss: 0.7025, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 049, Loss: 0.7030, Val: 0.9423, Test: 0.9048\n",
            "Epoch: 050, Loss: 0.7011, Val: 0.9423, Test: 0.9048\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "VWhUwO_-mL2s",
        "cb7pp6W7-WJ2"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}